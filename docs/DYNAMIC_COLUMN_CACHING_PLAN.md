# Dynamic Column Caching Plan for ValueAwareLapperCache

**Note: This is an unscrutinized plan generated by Claude AI. The ideas and implementation details presented here require thorough review, validation, and testing before any production use.**

## Overview

This document outlines a plan to implement adaptive tag/column inclusion for `ValueAwareLapperCache`. The core idea is to separate tags into tiers based on query frequency, storing only frequently-queried tags in the high-performance interval cache while maintaining less-frequently-queried tags in secondary storage. This approach aims to minimize memory consumption and maximize query performance for common query patterns.

## Problem Statement

Currently, all tags are included in the interval merge key, which leads to:
- **Memory bloat**: Storing every unique combination of all tags
- **Slower merging**: Comparing more fields during interval creation
- **Cache inefficiency**: Large cache size with potentially unnecessary granularity
- **Performance degradation**: High-cardinality tags that are rarely queried still impact every operation

## Solution: Tiered Tag Architecture

### Core Concept

Separate tags into three tiers:
1. **Primary Tags**: Included in merge key, fully indexed, optimized for queries
2. **Secondary Tags**: Stored but not indexed, accessible with performance penalty
3. **Excluded Tags**: Not stored at all (configurable based on needs)

This allows queries on primary tags to remain fast while still supporting queries on secondary tags when needed.

## Design Specification

### 1. Tag Classification System

```rust
use std::collections::{HashMap, HashSet, BTreeMap};
use std::sync::{Arc, RwLock};

#[derive(Debug, Clone)]
pub struct TagClassification {
    /// Tags that are indexed in the interval cache
    pub primary_tags: HashSet<String>,

    /// Tags that are stored but not indexed
    pub secondary_tags: HashSet<String>,

    /// Tags that are not stored at all
    pub excluded_tags: HashSet<String>,

    /// Configuration parameters
    pub config: ClassificationConfig,
}

#[derive(Debug, Clone)]
pub struct ClassificationConfig {
    /// Maximum number of primary tags
    pub max_primary_tags: usize,

    /// Minimum query frequency for primary tag promotion
    pub primary_promotion_threshold: f64,

    /// Maximum query frequency for primary tag demotion
    pub primary_demotion_threshold: f64,

    /// Whether to automatically adapt based on query patterns
    pub enable_adaptive_learning: bool,
}

impl Default for ClassificationConfig {
    fn default() -> Self {
        Self {
            max_primary_tags: 5,
            primary_promotion_threshold: 0.3,  // Used in 30% of queries
            primary_demotion_threshold: 0.01,  // Used in less than 1% of queries
            enable_adaptive_learning: true,
        }
    }
}

impl TagClassification {
    /// Create classification from query statistics
    pub fn from_statistics(stats: &QueryStatistics, config: ClassificationConfig) -> Self {
        let mut tags_by_frequency: Vec<_> = stats.tag_query_counts.iter()
            .map(|(tag, count)| {
                let frequency = *count as f64 / stats.total_queries as f64;
                (tag.clone(), frequency)
            })
            .collect();

        // Sort by frequency (descending)
        tags_by_frequency.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        let mut primary_tags = HashSet::new();
        let mut secondary_tags = HashSet::new();
        let mut excluded_tags = HashSet::new();

        for (tag, frequency) in tags_by_frequency {
            if primary_tags.len() < config.max_primary_tags && frequency >= config.primary_promotion_threshold {
                primary_tags.insert(tag);
            } else if frequency >= 0.001 {  // Accessed at least occasionally
                secondary_tags.insert(tag);
            } else {
                excluded_tags.insert(tag);
            }
        }

        Self {
            primary_tags,
            secondary_tags,
            excluded_tags,
            config,
        }
    }

    /// Create manual classification (for known query patterns)
    pub fn manual(primary: Vec<&str>, secondary: Vec<&str>) -> Self {
        Self {
            primary_tags: primary.into_iter().map(|s| s.to_string()).collect(),
            secondary_tags: secondary.into_iter().map(|s| s.to_string()).collect(),
            excluded_tags: HashSet::new(),
            config: ClassificationConfig {
                enable_adaptive_learning: false,
                ..Default::default()
            },
        }
    }

    /// Check if reclassification is recommended based on new statistics
    pub fn recommend_reclassification(&self, stats: &QueryStatistics) -> Option<Reclassification> {
        if !self.config.enable_adaptive_learning {
            return None;
        }

        let mut promotions = Vec::new();
        let mut demotions = Vec::new();

        for (tag, count) in &stats.tag_query_counts {
            let frequency = *count as f64 / stats.total_queries as f64;

            if self.secondary_tags.contains(tag) && frequency > self.config.primary_promotion_threshold {
                promotions.push(tag.clone());
            } else if self.primary_tags.contains(tag) && frequency < self.config.primary_demotion_threshold {
                demotions.push(tag.clone());
            }
        }

        // Check if we're within limits
        let new_primary_count = self.primary_tags.len() + promotions.len() - demotions.len();
        if new_primary_count > self.config.max_primary_tags {
            // Need to demote more tags
            promotions.truncate(self.config.max_primary_tags - self.primary_tags.len() + demotions.len());
        }

        if !promotions.is_empty() || !demotions.is_empty() {
            Some(Reclassification { promotions, demotions })
        } else {
            None
        }
    }
}
```

### 2. Tiered Cache Structure

```rust
pub struct TieredTagCache<V: Clone + Eq + Ord + std::hash::Hash + Send + Sync> {
    /// Primary interval cache - only indexes primary tags
    primary_cache: ValueAwareLapperCache<CompactTagSet>,

    /// Secondary storage for full row data
    secondary_storage: Arc<RwLock<SecondaryStorage<V>>>,

    /// Tag classification
    classification: Arc<RwLock<TagClassification>>,

    /// Query performance tracking
    query_tracker: Arc<RwLock<QueryTracker>>,

    /// Cache configuration
    config: TieredCacheConfig,
}

#[derive(Clone, Debug, Hash, Eq, PartialEq, Ord, PartialOrd)]
pub struct CompactTagSet {
    /// Hash of primary tags for fast comparison
    tag_hash: u64,

    /// The actual primary tags
    tags: Arc<BTreeMap<String, ArrowValue>>,

    /// Timestamp range for this tagset
    time_range: std::ops::Range<u64>,
}

pub struct SecondaryStorage<V> {
    /// Maps from (primary_tag_hash, timestamp) -> full row data
    data: BTreeMap<(u64, u64), Arc<FullRowData<V>>>,

    /// Bloom filters for quick negative lookups on secondary tags
    bloom_filters: HashMap<String, BloomFilter>,

    /// Optional indices for secondary tags (trade memory for query speed)
    secondary_indices: Option<SecondaryIndices>,

    /// Statistics
    stats: StorageStats,
}

pub struct FullRowData<V> {
    /// Primary tags (duplicated for fast access)
    primary_tags: BTreeMap<String, ArrowValue>,

    /// Secondary tags
    secondary_tags: BTreeMap<String, ArrowValue>,

    /// Field values (if applicable)
    fields: BTreeMap<String, ArrowValue>,

    /// The actual value stored
    value: V,
}

pub struct SecondaryIndices {
    /// Maps from (tag_name, tag_value) -> list of (primary_hash, timestamp)
    tag_indices: HashMap<String, BTreeMap<ArrowValue, Vec<(u64, u64)>>>,

    /// Memory usage tracking
    memory_usage: usize,
}

#[derive(Debug, Clone)]
pub struct TieredCacheConfig {
    /// Enable bloom filters for secondary tags
    pub use_bloom_filters: bool,

    /// Enable secondary tag indices (trades memory for query speed)
    pub use_secondary_indices: bool,

    /// Maximum memory for secondary indices (bytes)
    pub max_secondary_index_memory: usize,

    /// Enable query result caching
    pub enable_query_cache: bool,

    /// Query cache size (number of entries)
    pub query_cache_size: usize,
}

impl Default for TieredCacheConfig {
    fn default() -> Self {
        Self {
            use_bloom_filters: true,
            use_secondary_indices: false,  // Disabled by default to save memory
            max_secondary_index_memory: 100 * 1024 * 1024,  // 100MB
            enable_query_cache: true,
            query_cache_size: 1000,
        }
    }
}
```

### 3. Query Execution Engine

```rust
pub struct QueryPredicate {
    /// Conditions on primary tags
    primary_conditions: Vec<TagCondition>,

    /// Conditions on secondary tags
    secondary_conditions: Vec<TagCondition>,

    /// Time range
    time_range: std::ops::Range<u64>,
}

pub struct TagCondition {
    tag_name: String,
    operator: ComparisonOperator,
    value: ArrowValue,
}

pub enum ComparisonOperator {
    Equals,
    NotEquals,
    In(Vec<ArrowValue>),
    NotIn(Vec<ArrowValue>),
    Like(String),  // For string pattern matching
}

impl<V: Clone + Eq + Ord + std::hash::Hash + Send + Sync> TieredTagCache<V> {
    pub fn query(&self, predicate: &QueryPredicate) -> Result<QueryResult<V>, QueryError> {
        // Track query for adaptive learning
        self.query_tracker.write().unwrap().track_query(predicate);

        // Check query cache first
        if self.config.enable_query_cache {
            if let Some(cached) = self.check_query_cache(predicate) {
                return Ok(cached);
            }
        }

        let result = if predicate.secondary_conditions.is_empty() {
            // Fast path: only primary tags
            self.execute_primary_query(predicate)
        } else if predicate.primary_conditions.is_empty() {
            // Slow path: only secondary tags
            self.execute_secondary_scan(predicate)
        } else {
            // Mixed path: filter by primary first, then secondary
            self.execute_mixed_query(predicate)
        }?;

        // Cache the result
        if self.config.enable_query_cache {
            self.cache_query_result(predicate, &result);
        }

        Ok(result)
    }

    fn execute_primary_query(&self, predicate: &QueryPredicate) -> Result<QueryResult<V>, QueryError> {
        // Use the primary interval cache
        let intervals = self.primary_cache.query_range(predicate.time_range.clone());

        // Filter by primary conditions
        let matching_tagsets: Vec<_> = intervals.into_iter()
            .filter(|tagset| self.matches_primary_conditions(&tagset.tags, &predicate.primary_conditions))
            .collect();

        // Fetch full row data
        let mut results = Vec::new();
        let storage = self.secondary_storage.read().unwrap();

        for tagset in matching_tagsets {
            // Get all rows for this primary tagset in the time range
            let rows = storage.get_rows_for_tagset(tagset.tag_hash, &predicate.time_range);
            results.extend(rows);
        }

        Ok(QueryResult {
            rows: results,
            execution_stats: ExecutionStats {
                execution_type: ExecutionType::PrimaryOnly,
                rows_scanned: results.len(),
                indices_used: vec!["primary_interval_cache".to_string()],
            },
        })
    }

    fn execute_secondary_scan(&self, predicate: &QueryPredicate) -> Result<QueryResult<V>, QueryError> {
        let storage = self.secondary_storage.read().unwrap();

        // Check bloom filters first for quick negative results
        if self.config.use_bloom_filters {
            for condition in &predicate.secondary_conditions {
                if !storage.might_contain_tag(&condition.tag_name, &condition.value) {
                    // Definitely doesn't exist
                    return Ok(QueryResult::empty());
                }
            }
        }

        // Check if we have secondary indices
        if self.config.use_secondary_indices {
            if let Some(ref indices) = storage.secondary_indices {
                return self.execute_indexed_secondary_query(predicate, indices);
            }
        }

        // Fall back to full scan
        self.execute_full_secondary_scan(predicate, &storage)
    }

    fn execute_mixed_query(&self, predicate: &QueryPredicate) -> Result<QueryResult<V>, QueryError> {
        // First, get candidates from primary index
        let primary_intervals = self.primary_cache.query_range(predicate.time_range.clone());

        let primary_matches: Vec<_> = primary_intervals.into_iter()
            .filter(|tagset| self.matches_primary_conditions(&tagset.tags, &predicate.primary_conditions))
            .collect();

        // Then filter by secondary conditions
        let mut results = Vec::new();
        let storage = self.secondary_storage.read().unwrap();

        for tagset in primary_matches {
            let rows = storage.get_rows_for_tagset(tagset.tag_hash, &predicate.time_range);

            // Filter by secondary conditions
            for row in rows {
                if self.matches_secondary_conditions(&row.secondary_tags, &predicate.secondary_conditions) {
                    results.push(row);
                }
            }
        }

        Ok(QueryResult {
            rows: results,
            execution_stats: ExecutionStats {
                execution_type: ExecutionType::Mixed,
                rows_scanned: results.len(),
                indices_used: vec!["primary_interval_cache".to_string()],
            },
        })
    }

    fn matches_primary_conditions(&self, tags: &BTreeMap<String, ArrowValue>, conditions: &[TagCondition]) -> bool {
        conditions.iter().all(|cond| self.evaluate_condition(tags, cond))
    }

    fn matches_secondary_conditions(&self, tags: &BTreeMap<String, ArrowValue>, conditions: &[TagCondition]) -> bool {
        conditions.iter().all(|cond| self.evaluate_condition(tags, cond))
    }

    fn evaluate_condition(&self, tags: &BTreeMap<String, ArrowValue>, condition: &TagCondition) -> bool {
        match tags.get(&condition.tag_name) {
            Some(value) => match &condition.operator {
                ComparisonOperator::Equals => value == &condition.value,
                ComparisonOperator::NotEquals => value != &condition.value,
                ComparisonOperator::In(values) => values.contains(value),
                ComparisonOperator::NotIn(values) => !values.contains(value),
                ComparisonOperator::Like(pattern) => {
                    // Simple pattern matching for strings
                    if let (ArrowValue::String(v), ArrowValue::String(p)) = (value, &condition.value) {
                        v.contains(p)
                    } else {
                        false
                    }
                }
            },
            None => false,  // Tag not present
        }
    }
}
```

### 4. Query Tracking and Adaptive Learning

```rust
pub struct QueryTracker {
    /// Count of queries per tag
    tag_query_counts: HashMap<String, usize>,

    /// Total number of queries
    total_queries: usize,

    /// Query patterns (for more advanced analysis)
    query_patterns: Vec<QueryPattern>,

    /// Last reclassification timestamp
    last_reclassification: std::time::Instant,

    /// Reclassification interval
    reclassification_interval: std::time::Duration,
}

#[derive(Debug, Clone)]
pub struct QueryPattern {
    /// Tags used together in queries
    tag_combination: Vec<String>,

    /// Frequency of this pattern
    frequency: usize,

    /// Average execution time
    avg_execution_time: std::time::Duration,
}

impl QueryTracker {
    pub fn new() -> Self {
        Self {
            tag_query_counts: HashMap::new(),
            total_queries: 0,
            query_patterns: Vec::new(),
            last_reclassification: std::time::Instant::now(),
            reclassification_interval: std::time::Duration::from_secs(3600), // 1 hour
        }
    }

    pub fn track_query(&mut self, predicate: &QueryPredicate) {
        // Track individual tag usage
        for condition in &predicate.primary_conditions {
            *self.tag_query_counts.entry(condition.tag_name.clone()).or_insert(0) += 1;
        }

        for condition in &predicate.secondary_conditions {
            *self.tag_query_counts.entry(condition.tag_name.clone()).or_insert(0) += 1;
        }

        self.total_queries += 1;

        // Track query patterns
        let mut tags_in_query: Vec<String> = predicate.primary_conditions.iter()
            .chain(predicate.secondary_conditions.iter())
            .map(|c| c.tag_name.clone())
            .collect();
        tags_in_query.sort();

        if let Some(pattern) = self.query_patterns.iter_mut()
            .find(|p| p.tag_combination == tags_in_query) {
            pattern.frequency += 1;
        } else {
            self.query_patterns.push(QueryPattern {
                tag_combination: tags_in_query,
                frequency: 1,
                avg_execution_time: std::time::Duration::from_millis(0),
            });
        }
    }

    pub fn should_reclassify(&self) -> bool {
        self.last_reclassification.elapsed() > self.reclassification_interval
    }

    pub fn get_statistics(&self) -> QueryStatistics {
        QueryStatistics {
            tag_query_counts: self.tag_query_counts.clone(),
            total_queries: self.total_queries,
            popular_patterns: self.get_popular_patterns(),
        }
    }

    fn get_popular_patterns(&self) -> Vec<QueryPattern> {
        let mut patterns = self.query_patterns.clone();
        patterns.sort_by_key(|p| std::cmp::Reverse(p.frequency));
        patterns.truncate(10);  // Top 10 patterns
        patterns
    }
}

#[derive(Debug, Clone)]
pub struct QueryStatistics {
    pub tag_query_counts: HashMap<String, usize>,
    pub total_queries: usize,
    pub popular_patterns: Vec<QueryPattern>,
}

#[derive(Debug)]
pub struct Reclassification {
    pub promotions: Vec<String>,
    pub demotions: Vec<String>,
}
```

### 5. Bloom Filter Implementation

```rust
pub struct BloomFilter {
    bits: BitVec,
    num_hashes: usize,
    size: usize,
}

impl BloomFilter {
    pub fn new(expected_items: usize, false_positive_rate: f64) -> Self {
        let size = Self::optimal_size(expected_items, false_positive_rate);
        let num_hashes = Self::optimal_num_hashes(size, expected_items);

        Self {
            bits: BitVec::from_elem(size, false),
            num_hashes,
            size,
        }
    }

    fn optimal_size(n: usize, p: f64) -> usize {
        let ln2 = std::f64::consts::LN_2;
        ((-1.0 * n as f64 * p.ln()) / (ln2 * ln2)).ceil() as usize
    }

    fn optimal_num_hashes(m: usize, n: usize) -> usize {
        let ln2 = std::f64::consts::LN_2;
        ((m as f64 / n as f64) * ln2).ceil() as usize
    }

    pub fn insert(&mut self, value: &ArrowValue) {
        let hash = self.hash(value);
        for i in 0..self.num_hashes {
            let index = (hash.wrapping_add(i as u64).wrapping_mul(hash)) as usize % self.size;
            self.bits.set(index, true);
        }
    }

    pub fn might_contain(&self, value: &ArrowValue) -> bool {
        let hash = self.hash(value);
        for i in 0..self.num_hashes {
            let index = (hash.wrapping_add(i as u64).wrapping_mul(hash)) as usize % self.size;
            if !self.bits.get(index).unwrap_or(false) {
                return false;
            }
        }
        true
    }

    fn hash(&self, value: &ArrowValue) -> u64 {
        use std::hash::{Hash, Hasher};
        use std::collections::hash_map::DefaultHasher;

        let mut hasher = DefaultHasher::new();
        value.hash(&mut hasher);
        hasher.finish()
    }
}
```

### 6. Cache Building and Rebuilding

```rust
impl<V: Clone + Eq + Ord + std::hash::Hash + Send + Sync> TieredTagCache<V> {
    /// Build cache with manual classification
    pub fn build_with_classification(
        data: Vec<(u64, RecordBatchRow)>,
        classification: TagClassification,
        config: TieredCacheConfig,
    ) -> Result<Self, CacheBuildError> {
        // Separate data into primary and secondary components
        let mut primary_data = Vec::new();
        let mut secondary_storage = SecondaryStorage::new(config.clone());

        for (timestamp, row) in data {
            let (primary_tags, secondary_tags) = Self::split_tags(&row, &classification);

            // Create compact tagset for primary cache
            let compact = CompactTagSet {
                tag_hash: Self::hash_tags(&primary_tags),
                tags: Arc::new(primary_tags.clone()),
                time_range: timestamp..timestamp + 1,
            };

            primary_data.push((timestamp, compact.clone()));

            // Store full row in secondary storage
            let full_row = FullRowData {
                primary_tags,
                secondary_tags: secondary_tags.clone(),
                fields: row.values.clone(),
                value: row.clone(),
            };

            secondary_storage.insert(compact.tag_hash, timestamp, Arc::new(full_row));

            // Update bloom filters
            if config.use_bloom_filters {
                for (tag, value) in &secondary_tags {
                    secondary_storage.add_to_bloom(tag, value);
                }
            }
        }

        // Build primary interval cache
        let sorted_primary = SortedData::from_unsorted(primary_data);
        let primary_cache = ValueAwareLapperCache::from_sorted(sorted_primary)?;

        Ok(Self {
            primary_cache,
            secondary_storage: Arc::new(RwLock::new(secondary_storage)),
            classification: Arc::new(RwLock::new(classification)),
            query_tracker: Arc::new(RwLock::new(QueryTracker::new())),
            config,
        })
    }

    /// Build with adaptive classification based on sample queries
    pub fn build_adaptive(
        data: Vec<(u64, RecordBatchRow)>,
        sample_queries: &[QueryPredicate],
    ) -> Result<Self, CacheBuildError> {
        // Run sample queries to determine tag importance
        let mut tracker = QueryTracker::new();
        for query in sample_queries {
            tracker.track_query(query);
        }

        let stats = tracker.get_statistics();
        let classification = TagClassification::from_statistics(&stats, ClassificationConfig::default());

        Self::build_with_classification(data, classification, TieredCacheConfig::default())
    }

    /// Rebuild cache with new classification
    pub fn rebuild_with_classification(&mut self, new_classification: TagClassification) -> Result<(), CacheBuildError> {
        // Extract all data from current cache
        let data = self.extract_all_data();

        // Build new cache with new classification
        let new_cache = Self::build_with_classification(data, new_classification, self.config.clone())?;

        // Replace self with new cache
        *self = new_cache;

        Ok(())
    }

    fn split_tags(
        row: &RecordBatchRow,
        classification: &TagClassification,
    ) -> (BTreeMap<String, ArrowValue>, BTreeMap<String, ArrowValue>) {
        let mut primary = BTreeMap::new();
        let mut secondary = BTreeMap::new();

        for (key, value) in &row.values {
            if classification.primary_tags.contains(key) {
                primary.insert(key.clone(), value.clone());
            } else if classification.secondary_tags.contains(key) {
                secondary.insert(key.clone(), value.clone());
            }
            // Excluded tags are simply not stored
        }

        (primary, secondary)
    }

    fn hash_tags(tags: &BTreeMap<String, ArrowValue>) -> u64 {
        use std::hash::{Hash, Hasher};
        use std::collections::hash_map::DefaultHasher;

        let mut hasher = DefaultHasher::new();
        for (key, value) in tags {
            key.hash(&mut hasher);
            value.hash(&mut hasher);
        }
        hasher.finish()
    }
}
```

## Usage Examples

### Example 1: Manual Configuration for Known Patterns

```rust
// For metrics data where we know the important tags
let classification = TagClassification::manual(
    vec!["host", "service", "environment"],  // Primary tags (always fast)
    vec!["pod", "instance", "job", "datacenter"],  // Secondary tags (stored but slower)
);

let config = TieredCacheConfig {
    use_bloom_filters: true,
    use_secondary_indices: false,  // Save memory
    enable_query_cache: true,
    query_cache_size: 1000,
    ..Default::default()
};

let cache = TieredTagCache::build_with_classification(data, classification, config)?;

// Fast query on primary tags only
let query = QueryPredicate::new()
    .with_primary("host", Equals, "server-001")
    .with_primary("service", Equals, "api")
    .with_time_range(start..end);

let results = cache.query(&query)?;  // Fast execution

// Slower query including secondary tags
let query = QueryPredicate::new()
    .with_primary("host", Equals, "server-001")
    .with_secondary("pod", Like, "api-pod-*")
    .with_time_range(start..end);

let results = cache.query(&query)?;  // Slower but still functional
```

### Example 2: Adaptive Configuration with Learning

```rust
// Build cache with adaptive classification
let cache = TieredTagCache::build_adaptive(data, &sample_queries)?;

// Use the cache for a while
for _ in 0..10000 {
    let query = generate_query();
    cache.query(&query)?;
}

// Check if reclassification is recommended
let tracker = cache.query_tracker.read().unwrap();
if tracker.should_reclassify() {
    let stats = tracker.get_statistics();
    let classification = cache.classification.read().unwrap();

    if let Some(reclassification) = classification.recommend_reclassification(&stats) {
        println!("Reclassification recommended:");
        println!("  Promote to primary: {:?}", reclassification.promotions);
        println!("  Demote to secondary: {:?}", reclassification.demotions);

        // Apply reclassification
        let new_classification = classification.apply_reclassification(reclassification);
        cache.rebuild_with_classification(new_classification)?;
    }
}
```

### Example 3: Memory-Optimized Configuration

```rust
// Configuration for memory-constrained environments
let classification = TagClassification {
    primary_tags: hashset!["host", "service"],  // Only the most critical tags
    secondary_tags: hashset!["environment", "region"],  // A few important ones
    excluded_tags: all_other_tags,  // Don't store rarely used tags
    config: ClassificationConfig {
        max_primary_tags: 3,  // Very restrictive
        enable_adaptive_learning: false,  // Manual control only
        ..Default::default()
    },
};

let config = TieredCacheConfig {
    use_bloom_filters: true,  // Small memory overhead, big query benefit
    use_secondary_indices: false,  // Save memory
    enable_query_cache: false,  // Save memory
    ..Default::default()
};

let cache = TieredTagCache::build_with_classification(data, classification, config)?;
```

## Performance Characteristics

### Query Performance by Type

| Query Type | Performance | Use Case |
|------------|------------|----------|
| Primary-only | O(log n) | Most common queries on important tags |
| Secondary-only with indices | O(log n) | Occasional queries on indexed secondary tags |
| Secondary-only without indices | O(n) | Rare queries, full scan required |
| Mixed (primary + secondary) | O(log n * m) | Filtered queries, where m is secondary selectivity |

### Memory Usage

| Component | Memory Usage | Can Disable |
|-----------|-------------|-------------|
| Primary interval cache | ~50-100 bytes per interval | No |
| Secondary storage | ~100-200 bytes per row | No |
| Bloom filters | ~10 bits per item per tag | Yes |
| Secondary indices | ~50 bytes per unique value | Yes |
| Query cache | Configurable (default 1000 entries) | Yes |

### Build Performance

- **Initial build**: O(n log n) for sorting + O(n) for categorization
- **Reclassification**: Requires full rebuild, O(n log n)
- **Incremental updates**: O(log n) for primary, O(1) for secondary

## Trade-offs and Considerations

### Advantages

1. **Significant memory reduction** (30-70% in typical cases)
2. **Faster queries on primary tags** (fewer intervals to search)
3. **Better cache locality** (smaller working set)
4. **Flexibility** to query all tags when needed
5. **Adaptive optimization** based on real usage
6. **Configurable trade-offs** between memory and query performance

### Disadvantages

1. **Query complexity** - Different performance for different tags
2. **Rebuild cost** - Reclassification requires full rebuild
3. **API complexity** - Users need to understand tag tiers
4. **Storage overhead** - Maintaining dual structures
5. **Learning curve** - Requires understanding of query patterns

### When to Use This Approach

**Good fit for:**
- High cardinality datasets (>100K unique tag combinations)
- Clear distinction between frequently and rarely queried tags
- Memory-constrained environments
- Read-heavy workloads with predictable patterns
- Systems where 80% of queries use 20% of tags

**Not recommended for:**
- Small datasets (<10K rows)
- Uniform query distribution across all tags
- Write-heavy workloads
- Systems requiring consistent query performance

## Implementation Plan

### Phase 1: Core Infrastructure (3-4 days)
- [ ] Implement `TagClassification` system
- [ ] Create `CompactTagSet` and `SecondaryStorage` structures
- [ ] Build basic tiered cache structure
- [ ] Unit tests for classification logic

### Phase 2: Query Engine (2-3 days)
- [ ] Implement query predicate splitting
- [ ] Build primary-only query path
- [ ] Build secondary scan query path
- [ ] Build mixed query path
- [ ] Query execution tests

### Phase 3: Optimizations (2-3 days)
- [ ] Add bloom filters
- [ ] Implement secondary indices (optional)
- [ ] Add query result caching
- [ ] Performance benchmarks

### Phase 4: Adaptive Learning (2-3 days)
- [ ] Implement `QueryTracker`
- [ ] Build reclassification logic
- [ ] Add rebuild capability
- [ ] Integration tests

### Phase 5: Production Readiness (2-3 days)
- [ ] Comprehensive testing
- [ ] Performance tuning
- [ ] Documentation
- [ ] Migration guides

## Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Wrong classification | Poor performance | Provide manual override; extensive testing |
| Rebuild disruption | Availability impact | Support online rebuild; version switching |
| Memory overhead | Increased usage | Configurable features; memory limits |
| Query confusion | User errors | Clear documentation; query analyzer tools |
| Performance regression | Slower queries | Benchmarking; fallback to full cache |

## Future Enhancements

1. **Columnar storage** for secondary tags (better compression)
2. **Incremental reclassification** without full rebuild
3. **Multi-level caching** (L1/L2/L3 tag tiers)
4. **Query optimizer** to automatically rewrite queries
5. **Cost-based optimization** considering memory and CPU
6. **Machine learning** for classification prediction
7. **Distributed caching** for very large datasets

## Conclusion

The tiered tag caching approach offers significant benefits for high-cardinality datasets with skewed query patterns. By separating frequently-queried tags from rarely-queried ones, we can achieve better memory efficiency and query performance for common cases while maintaining functionality for all queries. The adaptive learning capability ensures the system can optimize itself based on real usage patterns over time.